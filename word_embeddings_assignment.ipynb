{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "862ab42e-551a-4233-a1c5-8666c2cb28df",
   "metadata": {},
   "source": [
    "objective: to train skip gram model to convert words into vectors, once train we can provide words and it can give similar words based on vector repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7820d212-b27b-4154-8a54-4b530efcccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d15c1481-315b-4a35-9e63-bdb6fafc1109",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to clean text\n",
    "def preprocess_text(text):\n",
    "    text=text.lower()  #converting into lower case\n",
    "    text=re.sub(r'[^a-z\\s]','',text) #only keep letters and spaces\n",
    "    words=text.split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f8b1ce73-682a-41c7-a445-289f63152578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import skipgrams\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dot, Reshape, Dense\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Load & preprocess\n",
    "params = {\n",
    "    'input_file': 'mental_health_data.csv',\n",
    "    'output_file': 'embeddings.txt',\n",
    "    'window_size': 1,\n",
    "    'embedding_dim': 100,\n",
    "    'epochs': 50\n",
    "}\n",
    "\n",
    "df = pd.read_csv(params['input_file'])\n",
    "text = ' '.join(df['selftext'].dropna().astype(str).tolist())\n",
    "\n",
    "# --- 2. Tokenize\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "sequences = tokenizer.texts_to_sequences([text])[0]\n",
    "word2idx = tokenizer.word_index\n",
    "vocab_size = len(word2idx) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b60d3811-2f4d-4018-8b97-0d7e3a37fd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs, labels = skipgrams(sequences, vocabulary_size=vocab_size, window_size=params['window_size'])\n",
    "target_words, context_words = zip(*pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "edde2cb3-0b29-44b2-9fca-6cd324fbe45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">393,400</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
       "│                               │                           │                 │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dot_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                               │                           │                 │ embedding_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ reshape_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dot_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ reshape_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_layer (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m393,400\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
       "│                               │                           │                 │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dot_3 (\u001b[38;5;33mDot\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ embedding_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                               │                           │                 │ embedding_layer[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ reshape_2 (\u001b[38;5;33mReshape\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ dot_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │               \u001b[38;5;34m2\u001b[0m │ reshape_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">393,402</span> (1.50 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m393,402\u001b[0m (1.50 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">393,402</span> (1.50 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m393,402\u001b[0m (1.50 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_target = Input((1,))\n",
    "input_context = Input((1,))\n",
    "\n",
    "embedding = Embedding(vocab_size, params['embedding_dim'], input_length=1, name='embedding_layer')\n",
    "\n",
    "target_embed = embedding(input_target)\n",
    "context_embed = embedding(input_context)\n",
    "\n",
    "dot_product = Dot(axes=-1)([target_embed, context_embed])\n",
    "dot_product = Reshape((1,))(dot_product)\n",
    "\n",
    "output = Dense(1, activation='sigmoid')(dot_product)\n",
    "\n",
    "model = Model([input_target, input_context], output)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a3d42e77-16b3-4fa7-a11c-b4b30ec9e216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - loss: 0.6329\n",
      "Epoch 2/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - loss: 0.3638\n",
      "Epoch 3/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 5ms/step - loss: 0.2012\n",
      "Epoch 4/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 5ms/step - loss: 0.1489\n",
      "Epoch 5/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - loss: 0.1274\n",
      "Epoch 6/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - loss: 0.1186\n",
      "Epoch 7/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - loss: 0.1130\n",
      "Epoch 8/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 5ms/step - loss: 0.1058\n",
      "Epoch 9/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - loss: 0.1045\n",
      "Epoch 10/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - loss: 0.1015\n",
      "Epoch 11/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0996\n",
      "Epoch 12/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 5ms/step - loss: 0.0976\n",
      "Epoch 13/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 5ms/step - loss: 0.0937\n",
      "Epoch 14/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - loss: 0.0953\n",
      "Epoch 15/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - loss: 0.0924\n",
      "Epoch 16/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 5ms/step - loss: 0.0936\n",
      "Epoch 17/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 5ms/step - loss: 0.0913\n",
      "Epoch 18/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 5ms/step - loss: 0.0900\n",
      "Epoch 19/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - loss: 0.0902\n",
      "Epoch 20/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - loss: 0.0890\n",
      "Epoch 21/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - loss: 0.0902\n",
      "Epoch 22/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - loss: 0.0882\n",
      "Epoch 23/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 5ms/step - loss: 0.0881\n",
      "Epoch 24/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - loss: 0.0875\n",
      "Epoch 25/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 5ms/step - loss: 0.0882\n",
      "Epoch 26/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - loss: 0.0873\n",
      "Epoch 27/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - loss: 0.0872\n",
      "Epoch 28/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - loss: 0.0861\n",
      "Epoch 29/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - loss: 0.0857\n",
      "Epoch 30/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - loss: 0.0849\n",
      "Epoch 31/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - loss: 0.0852\n",
      "Epoch 32/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - loss: 0.0848\n",
      "Epoch 33/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - loss: 0.0835\n",
      "Epoch 34/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - loss: 0.0843\n",
      "Epoch 35/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - loss: 0.0855\n",
      "Epoch 36/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - loss: 0.0841\n",
      "Epoch 37/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - loss: 0.0839\n",
      "Epoch 38/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - loss: 0.0846\n",
      "Epoch 39/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - loss: 0.0848\n",
      "Epoch 40/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - loss: 0.0835\n",
      "Epoch 41/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - loss: 0.0824\n",
      "Epoch 42/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - loss: 0.0821\n",
      "Epoch 43/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - loss: 0.0839\n",
      "Epoch 44/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - loss: 0.0840\n",
      "Epoch 45/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - loss: 0.0829\n",
      "Epoch 46/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - loss: 0.0824\n",
      "Epoch 47/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - loss: 0.0817\n",
      "Epoch 48/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - loss: 0.0827\n",
      "Epoch 49/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - loss: 0.0814\n",
      "Epoch 50/50\n",
      "\u001b[1m4797/4797\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - loss: 0.0816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1a3d95f0ed0>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([np.array(target_words), np.array(context_words)],\n",
    "          np.array(labels),\n",
    "          epochs=params['epochs'],\n",
    "          verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0f7d38b9-24e1-49db-a558-676ce9af1950",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.get_layer('embedding_layer').get_weights()[0]\n",
    "\n",
    "with open(params['output_file'], 'w', encoding='utf-8') as f:\n",
    "    for word, i in word2idx.items():\n",
    "        vector = ' '.join(map(str, weights[i]))\n",
    "        f.write(f\"{word} {vector}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f670595e-d859-4db5-9868-99299e7f8f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First run this block once\n",
    "import numpy as np\n",
    "\n",
    "# Load embeddings\n",
    "def load_embeddings(file):\n",
    "    embs = {}\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            word = parts[0]\n",
    "            vec = np.array(parts[1:], dtype='float32')\n",
    "            embs[word] = vec\n",
    "    return embs\n",
    "\n",
    "embeddings = load_embeddings('embeddings.txt')\n",
    "\n",
    "# Cosine similarity\n",
    "def get_similar(word, top_n=5):\n",
    "    if word not in embeddings:\n",
    "        return f\"'{word}' not found in vocab\"\n",
    "    \n",
    "    w_vec = embeddings[word]\n",
    "    sims = {\n",
    "        other: np.dot(w_vec, vec) / (np.linalg.norm(w_vec) * np.linalg.norm(vec))\n",
    "        for other, vec in embeddings.items() if other != word\n",
    "    }\n",
    "    return sorted(sims.items(), key=lambda x: x[1], reverse=True)[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6020b5e4-91f5-49ab-b3bd-5a79ff93838f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('done', 0.37784165),\n",
       " ('do', 0.3407945),\n",
       " ('friends', 0.34033915),\n",
       " ('alcohol', 0.3311222),\n",
       " ('faze', 0.31826755)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similar(\"anxiety\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1e61ea83-3236-44d4-833e-05e8fff467d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('beer', 0.4320064),\n",
       " ('age', 0.42814207),\n",
       " ('monthly', 0.42456794),\n",
       " ('isolation', 0.4041774),\n",
       " ('girlfriend', 0.39877856)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similar(\"mental\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8f414e13-8e2b-49a3-81da-5c4f375677ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('noticed', 0.45851675),\n",
       " ('blood', 0.45535794),\n",
       " ('call', 0.4541829),\n",
       " ('friend', 0.44422624),\n",
       " ('isolated', 0.43215582)]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similar(\"live\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5f8646a8-9654-4476-9dfe-17641ebe4438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nicotine', 0.47712353),\n",
       " ('bit', 0.42128196),\n",
       " ('feet', 0.41915596),\n",
       " ('lot', 0.38061348),\n",
       " ('sound', 0.38026083)]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similar(\"death\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2b938f-453b-470f-b93a-3cf6cb47d4a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
